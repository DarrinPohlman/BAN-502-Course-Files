---
title: "RFAssignQuiz"
author: "Darrin"
date: "2025-02-09"
output: word_document
---

Random Forests
Libraries: For this assignment you will need the following libraries: tidyverse, tidymodels, caret, gridExtra,
vip, and ranger.

```{r, include = FALSE}
library(tidyverse)
library(tidymodels)
library(ranger) #for random forests
library(caret)
library(gridExtra)
library(vip) #variable importance
```

Load data from the CSData.csv file.  
```{r}
drug = read_csv("drug_data-2.csv")
```

Structure and summary
```{R}
str(drug)
summary(drug)
```

Read in the “drug_data.csv” dataset. This dataset deals with drug consumption in individuals across a wide
spectrum of countries, drugs, ages, etc. A description of the dataset is available here: http://archive.ics.uci.
edu/ml/datasets/Drug+consumption+%28quantified%29
This dataset (as is common with medical and healthcare datasets) requires quite a bit of cleaning and
preparation before analysis.
I’ll walk you through the cleaning before we start our random forest work.

Loading the Data The columns do not have names, so we’ll supply names via the names function.
names(drug) = c("ID", "Age", "Gender", "Education", "Country", "Ethnicity",
"Nscore", "Escore", "Oscore", "Ascore", "Cscore", "Impulsive",
"SS", "Alcohol", "Amphet", "Amyl", "Benzos", "Caff", "Cannabis",
"Choc", "Coke", "Crack", "Ecstasy", "Heroin", "Ketamine", "Legalh",
"LSD", "Meth", "Mushrooms", "Nicotine", "Semer", "VSA")
```{r}
names(drug) = c("ID", "Age", "Gender", "Education", "Country", "Ethnicity",
              "Nscore", "Escore", "Oscore", "Ascore", "Cscore", "Impulsive",
              "SS", "Alcohol", "Amphet", "Amyl", "Benzos", "Caff", "Cannabis",
              "Choc", "Coke", "Crack", "Ecstasy", "Heroin", "Ketamine", "Legalh",
              "LSD", "Meth", "Mushrooms", "Nicotine", "Semer", "VSA")

```

Next-up we change all CL0 and CL1 values to “No” and CL2, CL3, CL4, CL5, and CL6 values to “Yes”.
CL0 and CL1 imply the drug was never used or used over a decade ago. CL2 through CL6 imply more
recent drug use. The code below finds any CL0, CL1, etc. values in the data frame and replaces them with
the appropriate “No” or “Yes”.
drug[drug == "CL0"] = "No"
drug[drug == "CL1"] = "No"
drug[drug == "CL2"] = "Yes"
drug[drug == "CL3"] = "Yes"
drug[drug == "CL4"] = "Yes"
drug[drug == "CL5"] = "Yes"
drug[drug == "CL6"] = "Yes"
```{r}
drug[drug == "CL0"] = "No"
drug[drug == "CL1"] = "No"
drug[drug == "CL2"] = "Yes"
drug[drug == "CL3"] = "Yes"
drug[drug == "CL4"] = "Yes"
drug[drug == "CL5"] = "Yes"
drug[drug == "CL6"] = "Yes"
```

Next up we do a good bit of factor conversion and recoding. Note the use of mutate_at to target specific
ranges of variables. You may see a warning message about the use of the funs() function. It is OK to ignore
this.
drug_clean = drug %>% mutate_at(vars(Age:Ethnicity), funs(as_factor)) %>%
mutate(Age = factor(Age, labels = c("18_24", "25_34", "35_44", "45_54",
"55_64", "65_"))) %>%
mutate(Gender = factor(Gender, labels = c("Male", "Female"))) %>%
mutate(Education = factor(Education, labels = c("Under16", "At16", "At17", "At18",
"SomeCollege","ProfessionalCert",
"Bachelors", "Masters",
"Doctorate"))) %>%
mutate(Country = factor(Country, labels = c("USA", "NewZealand", "Other", "Australia",
"Ireland","Canada","UK"))) %>%
mutate(Ethnicity = factor(Ethnicity, labels = c("Black", "Asian", "White",
"White/Black", "Other",
"White/Asian", "Black/Asian"))) %>%
mutate_at(vars(Alcohol:VSA), funs(as_factor)) %>%
select(-ID)
```{r}
drug_clean = drug %>% mutate_at(vars(Age:Ethnicity), funs(as_factor)) %>%
        mutate(Age = factor(Age, labels = c("18_24", "25_34", "35_44", "45_54", "55_64", "65_"))) %>%
        mutate(Gender = factor(Gender, labels = c("Male", "Female"))) %>%
        mutate(Education = factor(Education, labels = c("Under16", "At16", "At17", "At18","SomeCollege","ProfessionalCert","Bachelors", "Masters","Doctorate")))%>%
        mutate(Country = factor(Country, labels = c("USA", "NewZealand", "Other", "Australia","Ireland","Canada","UK"))) %>%
        mutate(Ethnicity = factor(Ethnicity, labels = c("Black", "Asian", "White","White/Black", "Other","White/Asian", "Black/Asian"))) %>%
        mutate_at(vars(Alcohol:VSA), funs(as_factor)) %>%
        select(-ID)
```

Take a peek at the cleaned data to make sure we are all good before proceeding.
str(drug_clean)
```{r}
str(drug_clean)
```

We’ll focus on Nicotine use, so let’s get rid of the remaining drug use variables. We’ll use select for this.
drug_clean = drug_clean %>% select(!(Alcohol:Mushrooms)) %>% select(!(Semer:VSA))
Now we’re in business. Let’s get started with the tasks.
```{r}
drug_clean = drug_clean %>% select(!(Alcohol:Mushrooms)) %>% select(!(Semer:VSA))
```

Check for missing data 
```{r}
skim(drug_clean)
```


Question 1: Check for missing data in our “drug_clean” dataframe.  False
True/False: There is missingness in the dataset.

Now we'll split the data.  
```{r}
set.seed(1234) 
drug_split = initial_split(drug_clean, prop = 0.7, strata = Nicotine) #70% in training
train = training(drug_split)
test = testing(drug_split)
```
Question 2: Split the dataset into training (70%) and testing (30%) sets. Use a set.seed of 1234. Stratify
by the “Nicotine” variable.
How many rows are in the training set? 1318

Visualization  
```{r}
p1 = ggplot(train, aes(x = Age, fill = Nicotine)) + geom_bar(position = "fill")
p2 = ggplot(train, aes(x = Gender, fill = Nicotine)) + geom_bar(position = "fill")
p3 = ggplot(train, aes(x = Education, fill = Nicotine)) + geom_bar(position = "fill")
p4 = ggplot(train, aes(x = Country, fill = Nicotine)) + geom_bar(position = "fill")
grid.arrange(p1,p2,p3,p4)
```
```{r}
p1 = ggplot(train, aes(x = Ethnicity, fill = Nicotine)) + geom_bar(position = "fill")
p2 = ggplot(train, aes(x = Nscore, fill = Nicotine)) + geom_bar(position = "fill")
p3 = ggplot(train, aes(x = Escore, fill = Nicotine)) + geom_bar(position = "fill")
p4 = ggplot(train, aes(x = Oscore, fill = Nicotine)) + geom_bar(position = "fill")
grid.arrange(p1,p2,p3,p4)
```
```{r}
p1 = ggplot(train, aes(x = Ascore, fill = Nicotine)) + geom_bar(position = "fill")
p2 = ggplot(train, aes(x = Cscore, fill = Nicotine)) + geom_bar(position = "fill")
p3 = ggplot(train, aes(x = Impulsive, fill = Nicotine)) + geom_bar(position = "fill")
p4 = ggplot(train, aes(x = SS, fill = Nicotine)) + geom_bar(position = "fill")
grid.arrange(p1,p2,p3,p4)
```
Question 3: Create appropriate visualizations (12 in all) to examine the relationships between each variable
and “Nicotine”. Use grid.arrange (from the gridExtra package) to organize these visuals (perhaps in groups
of four visualizations?).
True/False: Individuals in the 18-24 age group are proportionally more likely to be Nicotine users than not.  True


Question 4: True/False: Individuals with higher “Impulsive” scores more likely to be Nicotine users than not.  True

Set up our folds for cross-validation  
```{r}
set.seed(123)
rf_folds = vfold_cv(train, v = 5)
```
Random Forest Model
```{r}
drug_recipe = recipe(Nicotine ~., train) %>%
  step_dummy(all_nominal(), -all_outcomes())

rf_model = rand_forest(mtry = tune(), min_n = tune(), trees = 100) %>% #add tuning of mtry and min_n parameters
  #setting trees to 100 here should also speed things up a bit, but more trees might be better
  set_engine("ranger", importance = "permutation") %>% #added importance metric
  set_mode("classification")

drug_wflow = 
  workflow() %>% 
  add_model(rf_model) %>% 
  add_recipe(drug_recipe)

rf_grid = grid_regular(
  mtry(range = c(2, 8)), #these values determined through significant trial and error
  min_n(range = c(5, 20)), #these values determined through significant trial and error
  levels = 10
)

set.seed(123)
rf_res_tuned = tune_grid(
  drug_wflow,
  resamples = rf_folds,
  grid = rf_grid #use the tuning grid
)
```


```{r}
rf_res_tuned %>%
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  select(mean, min_n, mtry) %>%
  pivot_longer(min_n:mtry,
    values_to = "value",
    names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "Accuracy")
```
An alternate view of the parameters  
```{r}
rf_res_tuned %>%
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  mutate(min_n = factor(min_n)) %>%
  ggplot(aes(mtry, mean, color = min_n)) +
  geom_line(alpha = 0.5, size = 1.5) +
  geom_point() +
  labs(y = "Accuracy")
```
Question 5: Create a random forest model (using the ranger package) on the training set to predict Nicotine
using all of the variables in the dataset. You 5-fold, k-fold cross-validation (random number seed of 123 for
the folds). Allow R to select mtry values between 2 and 8 and min_n values between 5 and 20. Use 10
levels in your “grid_regular” function. Set a random number seed of 123 for the tune_grid function. Use
100 trees.
NOTE: This model may take a few minutes to run. Be patient :)
Visualize the relationships between parameters and performance metrics.
The highest accuracy in this visualization is just greater than which value: B. 0.730
A. 0.725
B. 0.730
C. 0.720
D. 0.715

```{r}
best_rf = select_best(rf_res_tuned, metric = "accuracy")

final_rf = finalize_workflow(
  drug_wflow,
  best_rf
)

final_rf
```
```{r}
#fit the finalized workflow to our training data
final_rf_fit = fit(final_rf, train)
```
Check out variable importance
```{r}
final_rf_fit %>% pull_workflow_fit() %>% vip(geom = "point")
```
Question 6: Use the best mtry and min_n values from Question 5 to finalize the workflow and fit the model
to training set. Examine variable importance.
Which variable is most important? D. SS
A. Oscore
B. Cscore
C. Impulsive
D. SS

Predictions  
```{r}
trainpredrf = predict(final_rf_fit, train)
head(trainpredrf)
```

Confusion matrix
```{r}
confusionMatrix(trainpredrf$.pred_class, train$Nicotine, 
                positive = "Yes")
```
Question 7: To four decimal places, what is the accuracy of your model on the training set?  0.9165

Question 8: To four decimal places, what is the naive accuracy (training set)?  0.6707

Predictions on test
```{r}
testpredrf = predict(final_rf_fit, test)
head(testpredrf)
confusionMatrix(testpredrf$.pred_class, test$Nicotine, 
                positive = "Yes")
```
Question 9: To four decimal places, what is your model’s accuracy on the testing set?  0.6966


Question 10 The difference in accuracy between the training and testing sets implies?  B. Overfitting is likely occurring
A. Overfitting does not appear to be occurring
B. Overfitting is likely occurring
C. It is not clear whether or not overfitting is occurring